// app/lib/llm.js
import { GoogleGenerativeAI } from '@google/generative-ai';
import { locales } from './locales'; // ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ìœ„í•´ ì¶”ê°€
import { TIMEOUTS } from './constants';
// --- ğŸ‘‡ [ìˆ˜ì •] getErrorKey ì„í¬íŠ¸ ì œê±° (ì§ì ‘ í‚¤ ì‚¬ìš©) ---
// import { getErrorKey } from './errorHandler';

const genAI = new GoogleGenerativeAI(process.env.GOOGLE_GEMINI_API_KEY);

// JSON ì‘ë‹µ ì „ìš© ëª¨ë¸
const model = genAI.getGenerativeModel({
    model: "gemini-2.0-flash",
    generationConfig: {
        responseMimeType: "application/json",
    }
});

// ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì „ìš© ëª¨ë¸
const streamingModel = genAI.getGenerativeModel({
    model: "gemini-2.0-flash"
});


/**
 * ì„ íƒëœ LLM ê³µê¸‰ìì— ë”°ë¼ APIë¥¼ í˜¸ì¶œí•˜ê³ , ë¶„ì„ëœ ì‘ë‹µê³¼ ìŠ¬ë¡¯ì„ JSONìœ¼ë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
 * @param {string} prompt - ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€
 * @param {string} language - ì‘ë‹µ ì–¸ì–´ ('ko' ë˜ëŠ” 'en')
 * @param {Array} shortcuts - ìˆì»· ëª©ë¡
 * @param {string} llmProvider - ì‚¬ìš©í•  LLM ('gemini' or 'flowise')
 * @param {string} flowiseApiUrl - Flowise API URL
 * @returns {Promise<ReadableStream|object>} - Gemini/Flowise ìŠ¤íŠ¸ë¦¼ì˜ ê²½ìš° ReadableStream, ì—ëŸ¬ ì‹œ í‘œì¤€ ì—ëŸ¬ JSON ê°ì²´({ type: 'error', message: '...' })ë¥¼ ë°˜í™˜
 */
export async function getLlmResponse(prompt, language = 'ko', shortcuts = [], llmProvider, flowiseApiUrl) {
    console.log(`[getLlmResponse] Provider selected: ${llmProvider}`);
    if (llmProvider === 'flowise') {
        return getFlowiseStreamingResponse(prompt, flowiseApiUrl, language);
    }

    // Gemini ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©
    return getGeminiStreamingResponse(prompt, language, shortcuts);
}


/**
 * Flowise APIì— ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ì„ ë³´ë‚´ê³ , ì‘ë‹µ ìŠ¤íŠ¸ë¦¼(ReadableStream)ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
 * @param {string} prompt - ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€
 * @param {string} apiUrl - Flowise API URL
 * @param {string} language - ì˜¤ë¥˜ ë©”ì‹œì§€ ì–¸ì–´ ì„¤ì •ìš©
 * @returns {Promise<ReadableStream|object>} - Flowiseì˜ SSE ìŠ¤íŠ¸ë¦¼ ë˜ëŠ” í‘œì¤€ ì—ëŸ¬ ê°ì²´ { type: 'error', message: '...' }
 */
async function getFlowiseStreamingResponse(prompt, apiUrl, language = 'ko') {
    console.log(`[getFlowiseStreamingResponse] Called with apiUrl: ${apiUrl}`);

    if (!apiUrl) {
        console.error("[getFlowiseStreamingResponse] Error: Flowise API URL is not set.");
        // --- ğŸ‘‡ [ìˆ˜ì •] URL ë¶€ì¬ ì‹œ errorLLMFail ë©”ì‹œì§€ ì‚¬ìš© ---
        const message = locales[language]?.['errorLLMFail'] || 'Flowise API is not configured. Please try again later.';
        return {
            type: 'error',
            message: message
        };
        // --- ğŸ‘† [ìˆ˜ì •] ---
    }

    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), TIMEOUTS.LLM_REQUEST); // 30ì´ˆ íƒ€ì„ì•„ì›ƒ ì„¤ì •

    try {
        const requestBody = { question: prompt, streaming: true };
        console.log(`[getFlowiseStreamingResponse] Sending request to Flowise: ${apiUrl}`, requestBody);

        const response = await fetch(apiUrl, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify(requestBody),
            signal: controller.signal
        });

        clearTimeout(timeoutId);

        console.log(`[getFlowiseStreamingResponse] Received response status: ${response.status}`);

        if (!response.ok) {
            let errorBody = await response.text();
            try {
                const errorJson = JSON.parse(errorBody);
                errorBody = errorJson.message || errorBody;
            } catch (e) { /* ignore json parse error */ }
            console.error(`[getFlowiseStreamingResponse] Flowise API Error (${response.status}):`, errorBody);
            // --- ğŸ‘‡ [ìˆ˜ì •] HTTP ì˜¤ë¥˜ ì‹œ errorLLMFail ë©”ì‹œì§€ ì‚¬ìš© ---
            const message = locales[language]?.['errorLLMFail'] || 'Flowise API request failed. Please try again later.';
            return {
                type: 'error',
                message: message
            };
            // --- ğŸ‘† [ìˆ˜ì •] ---
        }

        console.log("[getFlowiseStreamingResponse] Response OK. Returning response body (stream).");
        return response.body;

    } catch (error) {
        clearTimeout(timeoutId);
        console.error("[getFlowiseStreamingResponse] API call failed:", error);

        // --- ğŸ‘‡ [ìˆ˜ì •] fetch ì˜¤ë¥˜ ì‹œ errorLLMFail ë©”ì‹œì§€ ì‚¬ìš© ---
        const message = locales[language]?.['errorLLMFail'] || 'Failed to call Flowise API. Please try again later.';
        return {
            type: 'error',
            message: message
        };
        // --- ğŸ‘† [ìˆ˜ì •] ---
    }
}


// Gemini ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ í•¨ìˆ˜
async function getGeminiStreamingResponse(prompt, language = 'ko', shortcuts = []) {
  console.log(`[getGeminiStreamingResponse] Called.`);
  try {
    const languageInstruction = language === 'en'
        ? "Please construct your 'response' field in English."
        : "ë°˜ë“œì‹œ 'response' í•„ë“œëŠ” í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.";

    const shortcutList = shortcuts.length > 0
      ? `Here is a list of available shortcuts the user can use:\n${JSON.stringify(shortcuts, null, 2)}`
      : "There are no shortcuts available.";

    const systemInstruction = `You are a powerful AI assistant. Your task is to analyze user input and generate a response in two parts, separated by '|||'.
1.  **First Part (JSON object for slots)**: Analyze the user's prompt to identify key entities (like locations, dates, times, names, etc.). Create a JSON object with a single key "slots" containing these key-value-pairs. If no specific entities are found, the value should be an empty object {}. Output this entire JSON object on a single line.
2.  **Second Part (Natural Language Response)**: After the JSON object and the '|||' separator, provide a helpful, conversational response to the user's prompt.
    * If the user's prompt is strongly related to a shortcut from the list below, recommend it using the format: "í˜¹ì‹œ ì•„ë˜ì™€ ê°™ì€ ê¸°ëŠ¥ì´ í•„ìš”í•˜ì‹ ê°€ìš”?\\n\\n[BUTTON:{shortcut.title}]".
    * If it relates to multiple shortcuts, use the format: "í˜¹ì‹œ ì•„ë˜ì™€ ê°™ì€ ê¸°ëŠ¥ì´ í•„ìš”í•˜ì‹ ê°€ìš”?\\n[BUTTON:Shortcut 1]\\n\\n[BUTTON:Shortcut 2]".
    * Otherwise, provide a general, helpful conversational response.

**EXAMPLE OUTPUT FORMAT**:
{"slots":{"destination":"Jeju Island","date":"November 5th"}}|||ë„¤, 11ì›” 5ì¼ì— ì œì£¼ë„ë¡œ ê°€ì‹œëŠ”êµ°ìš”! ì–´ë–¤ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?

**Available Shortcuts**:
${shortcutList}
`;

    const fullPrompt = `${systemInstruction}\n\n${languageInstruction}\n\nUser: ${prompt}`;

    console.log("[getGeminiStreamingResponse] Sending request to Gemini...");
    const result = await streamingModel.generateContentStream(fullPrompt);

    console.log("[getGeminiStreamingResponse] Received stream from Gemini. Creating ReadableStream...");
    const stream = new ReadableStream({
      async start(controller) {
        console.log("[getGeminiStreamingResponse] ReadableStream started. Reading chunks...");
        try {
          for await (const chunk of result.stream) {
            const chunkText = chunk && typeof chunk.text === 'function' ? chunk.text() : '';
            controller.enqueue(new TextEncoder().encode(chunkText));
          }
          console.log("[getGeminiStreamingResponse] Finished reading chunks. Closing controller.");
          controller.close();
        } catch (streamReadError) {
             console.error("[getGeminiStreamingResponse] Error reading stream:", streamReadError);
             controller.error(streamReadError);
        }
      }
    });

    return stream;

  } catch (error) {
    console.error("[getGeminiStreamingResponse] Gemini API Error:", error);
    // --- ğŸ‘‡ [ìˆ˜ì •] Gemini API ì˜¤ë¥˜ ì‹œ errorLLMFail ë©”ì‹œì§€ ì‚¬ìš© ---
    const message = locales[language]?.['errorLLMFail'] || 'Failed to call Gemini API. Please try again later.';
    return {
        type: 'error',
        message: message
    };
    // --- ğŸ‘† [ìˆ˜ì •] ---
  }
}

// getGeminiResponseWithSlots í•¨ìˆ˜ (JSON ì‘ë‹µ)
export async function getGeminiResponseWithSlots(prompt, language = 'ko', shortcuts = []) {
  try {
    const languageInstruction = language === 'en'
        ? "Please construct your 'response' field in English."
        : "ë°˜ë“œì‹œ 'response' í•„ë“œëŠ” í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.";

    const shortcutList = shortcuts.length > 0
      ? `Here is a list of available shortcuts the user can use:\n${JSON.stringify(shortcuts, null, 2)}`
      : "There are no shortcuts available.";

    const systemInstruction = `You are a powerful AI assistant that analyzes user input, extracts key information (slots), and generates a response. Your output MUST be a valid JSON object with two fields: "response" and "slots".

1.  **Analyze the user's prompt**: Identify key entities like locations, dates, times, names, numbers, etc.
2.  **Populate the "slots" object**: Create a key-value pair for each extracted entity. For example, if the user says "I want to go to Jeju Island on November 5th", the slots should be \`{ "destination": "Jeju Island", "date": "November 5th" }\`. If no specific entities are found, return an empty object \`{}\`.
3.  **Generate the "response" string**:
    * If the user's prompt is strongly related to a shortcut from the list below, recommend it using the format: "í˜¹ì‹œ ì•„ë˜ì™€ ê°™ì€ ê¸°ëŠ¥ì´ í•„ìš”í•˜ì‹ ê°€ìš”?\\n\\n[BUTTON:{shortcut.title}]".
    * If it relates to multiple shortcuts, use the format: "í˜¹ì‹œ ì•„ë˜ì™€ ê°™ì€ ê¸°ëŠ¥ì´ í•„ìš”í•˜ì‹ ê°€ìš”?\\n[BUTTON:Shortcut 1]\\n\\n[BUTTON:Shortcut 2]".
    * Otherwise, provide a general, helpful conversational response.
4.  **Combine into a single JSON object** and return it.

**Available Shortcuts**:
${shortcutList}
`;

    const fullPrompt = `${systemInstruction}\n\n${languageInstruction}\n\nUser: ${prompt}`;

    const result = await model.generateContent(fullPrompt);
    const responseText = result.response.text();

    // --- ğŸ‘‡ [ìˆ˜ì •] ì‘ë‹µ ìœ íš¨ì„± ê²€ì‚¬ ë° ì˜¤ë¥˜ ì²˜ë¦¬ ì¶”ê°€ ---
    try {
        const parsedResponse = JSON.parse(responseText);
        // "response" í•„ë“œê°€ ë¬¸ìì—´ì¸ì§€, "slots" í•„ë“œê°€ ê°ì²´ì¸ì§€ ê¸°ë³¸ì ì¸ ê²€ì‚¬
        if (typeof parsedResponse.response === 'string' && typeof parsedResponse.slots === 'object' && parsedResponse.slots !== null) {
            return parsedResponse;
        } else {
            console.error("Gemini API returned invalid JSON structure:", responseText);
            throw new Error("Invalid JSON structure received from LLM.");
        }
    } catch (parseError) {
        console.error("Error parsing Gemini JSON response:", parseError, "Raw response:", responseText);
        throw new Error("Failed to parse LLM response."); // ì—ëŸ¬ë¥¼ ë‹¤ì‹œ ë˜ì ¸ì„œ ìƒìœ„ catch ë¸”ë¡ì—ì„œ ì²˜ë¦¬
    }
    // --- ğŸ‘† [ìˆ˜ì •] ---

  } catch (error) {
    console.error("Gemini API Error (getGeminiResponseWithSlots):", error);
    // --- ğŸ‘‡ [ìˆ˜ì •] Gemini ì˜¤ë¥˜ ì‹œ errorLLMFail ë©”ì‹œì§€ ì‚¬ìš© ---
    return {
        response: locales[language]?.['errorLLMFail'] || "Sorry, there was a problem generating the response. Please try again later.",
        slots: {}
    };
    // --- ğŸ‘† [ìˆ˜ì •] ---
  }
}